import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Preprocess the data
x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values

# Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),  # Dropout layer to prevent overfitting
    Dense(10, activation='softmax')
])


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(x_train.reshape(-1, 28, 28, 1), y_train, epochs=5)

# Evaluate the model
test_loss, test_acc = model.evaluate(x_test.reshape(-1, 28, 28, 1), y_test, verbose=2)
print(f"Test accuracy: {test_acc}")

# Make predictions
predictions = model.predict(x_test.reshape(-1, 28, 28, 1))
model.save('model_weights.h5')




from tensorflow.keras.models import load_model

# Load the model
model = load_model('model_weights.h5')





import cv2

# Load the document image
document_image = cv2.imread('STAMP.jpg', cv2.IMREAD_GRAYSCALE)

# Preprocess the image
document_image = cv2.resize(document_image, (28, 28))
document_image = document_image / 255.0  # Normalize pixel values






import numpy as np

# Reshape the image for inference (add batch dimension)
input_image = np.expand_dims(document_image, axis=0)

# Make predictions
predictions = model.predict(input_image)

# Extract the digit or character with the highest confidence
digit = np.argmax(predictions)

print(f"Predicted digit: {digit}")



